{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2192f595",
   "metadata": {},
   "source": [
    "# Consumer Complaint Classification – Transformers \n",
    "\n",
    "## Introduction  \n",
    "\n",
    "The goal of this project is to develop a **text classification model** that categorizes **consumer complaints** into five financial categories using **transformer-based algorithms**.  \n",
    "\n",
    "The dataset, obtained from the **Consumer Financial Protection Bureau (CFPB)**, contains **over 2 million consumer complaints** from **2011 to 2024**. Each complaint is a textual **narrative** describing a financial issue, and these complaints have been labeled into **five main categories**:  \n",
    "\n",
    "- **Loans**  \n",
    "- **Credit Reporting**  \n",
    "- **Bank Accounts & Services**  \n",
    "- **Debt Collection**  \n",
    "- **Credit Card Services**  \n",
    "\n",
    "---\n",
    "\n",
    "## Data Understanding  \n",
    "\n",
    "The dataset originates from the **Consumer Complaint Database** maintained by the **Consumer Financial Protection Bureau (CFPB)**, a **U.S. federal agency** that mediates disputes between financial institutions and consumers. Consumers submit complaints through an **online form**, detailing their financial issues.  \n",
    "\n",
    "The dataset was **downloaded from the CFPB website** and underwent **preprocessing** to prepare it for NLP tasks. The key modifications include:  \n",
    "\n",
    "- Retaining only records where a **\"Consumer complaint narrative\"** is available.  \n",
    "- Reducing the dataset from **5,842,373** records to **2,023,066** entries.  \n",
    "- Renaming the **\"Consumer complaint narrative\"** column to **\"narrative\"** for ease of coding.  \n",
    "- Consolidating **18 original product categories** into **5 main categories (product_5)** to address overlaps in classification.  \n",
    "\n",
    "---\n",
    "\n",
    "## Consumer Complaint Classification Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fbd1110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# !pip install transformers datasets pandas numpy scikit-learn torch tqdm\n",
    "\n",
    "# --------------------\n",
    "# Standard Libraries\n",
    "# --------------------\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "# --------------------\n",
    "# Data Manipulation\n",
    "# --------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------------------\n",
    "# Visualization\n",
    "# --------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Machine Learning\n",
    "# --------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# --------------------\n",
    "# PyTorch & Transformers\n",
    "# --------------------\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    RobertaTokenizer, \n",
    "    RobertaForSequenceClassification\n",
    ")\n",
    "\n",
    "# --------------------\n",
    "# Progress Bar\n",
    "# --------------------\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Pickle\n",
    "# --------------------\n",
    "import pickle\n",
    "# --------------------\n",
    "# Set Seed for Reproducibility\n",
    "# --------------------\n",
    "def set_seed(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# --------------------\n",
    "# Device Configuration\n",
    "# --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a42b5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>product_5</th>\n",
       "      <th>narrative</th>\n",
       "      <th>Product</th>\n",
       "      <th>Date received</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>Timely response?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234</td>\n",
       "      <td>Credit Reporting</td>\n",
       "      <td>Dear Possible Financial Inc you guyss aree rep...</td>\n",
       "      <td>Credit reporting or other personal consumer re...</td>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account information incorrect</td>\n",
       "      <td>Possible Financial Inc</td>\n",
       "      <td>MI</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>Debt Collection</td>\n",
       "      <td>XXXX XXXX XXXX ( debt collector ), sent my boy...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Threatened to contact someone or share informa...</td>\n",
       "      <td>Talked to a third-party about your debt</td>\n",
       "      <td>BlueChip Financial</td>\n",
       "      <td>TX</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>257</td>\n",
       "      <td>Credit Reporting</td>\n",
       "      <td>I been receiving alerts my information was fou...</td>\n",
       "      <td>Credit reporting or other personal consumer re...</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>Credit inquiries on your report that you don't...</td>\n",
       "      <td>FC HoldCo LLC</td>\n",
       "      <td>SC</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271</td>\n",
       "      <td>Credit Reporting</td>\n",
       "      <td>Subject : Dispute of Inaccurate Information on...</td>\n",
       "      <td>Credit reporting or other personal consumer re...</td>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>Reporting company used your report improperly</td>\n",
       "      <td>CORELOGIC INC</td>\n",
       "      <td>GA</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276</td>\n",
       "      <td>Loans</td>\n",
       "      <td>They allowed me to use the account for about a...</td>\n",
       "      <td>Payday loan, title loan, personal loan, or adv...</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>Payday loan</td>\n",
       "      <td>Received a loan you didn't apply for</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MoneyLion Inc.</td>\n",
       "      <td>PA</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         product_5  \\\n",
       "0         234  Credit Reporting   \n",
       "1         240   Debt Collection   \n",
       "2         257  Credit Reporting   \n",
       "3         271  Credit Reporting   \n",
       "4         276             Loans   \n",
       "\n",
       "                                           narrative  \\\n",
       "0  Dear Possible Financial Inc you guyss aree rep...   \n",
       "1  XXXX XXXX XXXX ( debt collector ), sent my boy...   \n",
       "2  I been receiving alerts my information was fou...   \n",
       "3  Subject : Dispute of Inaccurate Information on...   \n",
       "4  They allowed me to use the account for about a...   \n",
       "\n",
       "                                             Product Date received  \\\n",
       "0  Credit reporting or other personal consumer re...    2024-07-27   \n",
       "1                                    Debt collection    2024-07-27   \n",
       "2  Credit reporting or other personal consumer re...    2024-07-23   \n",
       "3  Credit reporting or other personal consumer re...    2024-07-27   \n",
       "4  Payday loan, title loan, personal loan, or adv...    2024-07-26   \n",
       "\n",
       "        Sub-product                                              Issue  \\\n",
       "0  Credit reporting               Incorrect information on your report   \n",
       "1     I do not know  Threatened to contact someone or share informa...   \n",
       "2  Credit reporting                        Improper use of your report   \n",
       "3  Credit reporting                        Improper use of your report   \n",
       "4       Payday loan               Received a loan you didn't apply for   \n",
       "\n",
       "                                           Sub-issue                 Company  \\\n",
       "0                      Account information incorrect  Possible Financial Inc   \n",
       "1            Talked to a third-party about your debt      BlueChip Financial   \n",
       "2  Credit inquiries on your report that you don't...           FC HoldCo LLC   \n",
       "3      Reporting company used your report improperly           CORELOGIC INC   \n",
       "4                                                NaN          MoneyLion Inc.   \n",
       "\n",
       "  State Timely response?  \n",
       "0    MI              Yes  \n",
       "1    TX              Yes  \n",
       "2    SC              Yes  \n",
       "3    GA              Yes  \n",
       "4    PA              Yes  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/complaints.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88047f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Unnamed: 0' column\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd16359d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_5\n",
       "Bank Accounts and Services    10000\n",
       "Credit Card Services          10000\n",
       "Credit Reporting              10000\n",
       "Debt Collection               10000\n",
       "Loans                         10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define sample size per category\n",
    "sample_size = 10000\n",
    "\n",
    "df_resampled = df.groupby(\"product_5\").sample(n=sample_size, random_state=42)\n",
    "\n",
    "df_resampled = df_resampled.reset_index(drop=True)\n",
    "\n",
    "df_resampled[\"product_5\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "209c992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label mapping (int → class name):\n",
      "0: Bank Accounts and Services\n",
      "1: Credit Card Services\n",
      "2: Credit Reporting\n",
      "3: Debt Collection\n",
      "4: Loans\n"
     ]
    }
   ],
   "source": [
    "# Encode the labels (LabelEncoder: str → int)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(df_resampled['product_5'])\n",
    "\n",
    "# Create label mapping (int → str) for interpretation later\n",
    "label_mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}  # Optional reverse\n",
    "\n",
    "# Print the mapping for verification\n",
    "print(\"\\nLabel mapping (int → class name):\")\n",
    "for i, label in label_mapping.items():\n",
    "    print(f\"{i}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc1801e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 35000\n",
      "Validation set size: 7500\n",
      "Test set size: 7500\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df_resampled['narrative'].values,\n",
    "    encoded_labels,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=encoded_labels\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts,\n",
    "    temp_labels,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {len(train_texts)}\")\n",
    "print(f\"Validation set size: {len(val_texts)}\")\n",
    "print(f\"Test set size: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82465a4b",
   "metadata": {},
   "source": [
    "Transformers settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f59909d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SELECT MODEL TYPE ===\n",
    "robertA_base = False\n",
    "robertA_base_large = False\n",
    "distilbert = True  # Set the one you want to True\n",
    "\n",
    "distilbert_save= True\n",
    "robertA_base_save = False\n",
    "\n",
    "# === AUTOMATIC CONFIG BASED ON FLAGS ===\n",
    "if distilbert:\n",
    "    model_name = 'distilbert-base-uncased'\n",
    "    model_type = 'distilbert'\n",
    "    batch_size = 16  # You can keep it higher for smaller models\n",
    "    model_save_path = 'checkpoints_distilbert' if distilbert_save else None\n",
    "    metric_save_path = 'metrics_distilbert'\n",
    "elif robertA_base:\n",
    "    model_name = 'roberta-base'\n",
    "    model_type = 'roberta'\n",
    "    batch_size = 16\n",
    "    model_save_path= 'checkpoints_roberta' if robertA_base_save else None\n",
    "    metric_save_path = 'metrics_roberta'\n",
    "elif robertA_base_large:\n",
    "    model_name = 'roberta-large'\n",
    "    model_type = 'roberta'\n",
    "    batch_size = 8  # roberta-large is heavy — lower the batch size\n",
    "else:\n",
    "    raise ValueError(\"Please set one of the model flags to True.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60043dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset\n",
    "class ConsumerComplaintDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        text = text.strip()\n",
    "\n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bca8779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1edf7c46c6a647d5bade36454d60a23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67a73f66c4264ba5899283e028bf159a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "838f19d31b5b48f7b160fc522092a0e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93840408c41149f38697de4c3b5ba089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if distilbert:\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "elif robertA_base:\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "elif robertA_base_large:\n",
    "    tokenizer = RobertaTokenizer.from_pretrained('roberta-large')\n",
    "# Create datasets\n",
    "train_dataset = ConsumerComplaintDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = ConsumerComplaintDataset(val_texts, val_labels, tokenizer)\n",
    "test_dataset = ConsumerComplaintDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "batch_size = 16\n",
    "# Create data loaders\n",
    "if robertA_base_large:\n",
    "    batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ebd29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, epochs=4, learning_rate=5e-5, save_every_n_epochs=3, model_save_path=\"model\"):\n",
    "    # Prepare optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "    \n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    \n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=0, \n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Lists to store loss and accuracy\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    val_precisions = []\n",
    "    val_recalls = []\n",
    "    val_f1s = []\n",
    "    iteration_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        print('-' * 40)\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_dataloader, desc=\"Training\")\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Clear previous gradients\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_train_loss += loss.item()\n",
    "            iteration_losses.append(loss.item())\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip the norm of the gradients to 1.0\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            # Update parameters and learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        \n",
    "        for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass without gradient calculation\n",
    "            with torch.no_grad():\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            \n",
    "            # Store predictions and true labels\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        val_accuracy = accuracy_score(true_labels, predictions)\n",
    "        val_precision = precision_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "        val_recall = recall_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "        val_f1 = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_precisions.append(val_precision)\n",
    "        val_recalls.append(val_recall)\n",
    "        val_f1s.append(val_f1)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "        print(f\"Validation Recall: {val_recall:.4f}\")\n",
    "        print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(true_labels, predictions))\n",
    "\n",
    "        # === Save checkpoint every N epochs ===\n",
    "        if (epoch + 1) % save_every_n_epochs == 0:\n",
    "            checkpoint_dir = os.path.join(model_save_path, f\"epoch_{epoch + 1}\")\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            model.save_pretrained(checkpoint_dir)\n",
    "            try:\n",
    "                model.config.tokenizer.save_pretrained(checkpoint_dir)  # If tokenizer is attached\n",
    "            except:\n",
    "                pass  # Or pass tokenizer separately outside\n",
    "            print(f\"Checkpoint saved to {checkpoint_dir}\")\n",
    "            '''\n",
    "            metrics = {\n",
    "        'epoch': epoch + 1,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'iteration_losses': iteration_losses,\n",
    "        'val_precisions': val_precisions,\n",
    "        'val_recalls': val_recalls,\n",
    "        'val_f1s': val_f1s,\n",
    "        }\n",
    "    with open(os.path.join(metric_save_path, f\"metric_epoch_{epoch + 1}\"), 'wb') as f:\n",
    "        pickle.dump(metrics, f)\n",
    "        '''\n",
    "    return model, train_losses, val_losses, val_accuracies,  iteration_losses, val_precisions, val_recalls, val_f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa9c846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iteration_loss(iteration_losses):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(iteration_losses, label='Training Loss (per iteration)', linewidth=0.7)\n",
    "    plt.title('Training Loss per Iteration')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fccd268",
   "metadata": {},
   "source": [
    "## Plotting Validation Accuracy, Precision, Recall and F1 Score for each Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd9ad883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_metrics(val_accuracies, val_precisions, val_recalls, val_f1s):\n",
    "    epochs = list(range(1, len(val_accuracies) + 1))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, val_accuracies, label='Accuracy')\n",
    "    plt.plot(epochs, val_precisions, label='Precision')\n",
    "    plt.plot(epochs, val_recalls, label='Recall')\n",
    "    plt.plot(epochs, val_f1s, label='F1 Score')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Validation Metrics per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "184b5f3e4a844b46b6b0a76dc720eac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if model_type == 'distilbert':\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label_mapping),\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False\n",
    "    )\n",
    "elif model_type == 'roberta':\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label_mapping),\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False\n",
    "    )\n",
    "\n",
    "model = model.to(device)\n",
    "# === Training parameters ===\n",
    "epochs = 3\n",
    "learning_rate = 5e-5\n",
    "\n",
    "# === Train the model ===\n",
    "model, train_losses, val_losses, val_accuracies, iteration_losses, val_precisions, val_recalls, val_f1s = train_model(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    save_every_n_epochs=3,\n",
    "    model_save_path=model_save_path\n",
    ")\n",
    "'''\n",
    "# === Save the model ===\n",
    "# Convert model name (e.g., \"distilbert-base-uncased\") into a clean folder name\n",
    "model_save_path = f\"{model_name.replace('/', '_')}_consumer_complaints_model\"\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b894e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iteration_loss(iteration_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60667f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_metrics(val_accuracies, val_precisions, val_recalls, val_f1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass without gradient calculation\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "        \n",
    "        # Get predictions\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        \n",
    "        # Store predictions and true labels\n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, predictions))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=label_encoder.classes_, \n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title('Confusion Matrix', fontsize=16)\n",
    "    plt.xlabel('Predicted Label', fontsize=14)\n",
    "    plt.ylabel('True Label', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'true_labels': true_labels,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "# Add missing import for confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_results = evaluate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63029298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_complaint_category(text, model, tokenizer, label_mapping):\n",
    "    # Tokenize the text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move inputs to the device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward pass without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Get the predictions\n",
    "    logits = outputs.logits\n",
    "    prediction_id = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Get the predicted category\n",
    "    predicted_category = label_mapping[prediction_id]\n",
    "    \n",
    "    return predicted_category\n",
    "\n",
    "# Example usage\n",
    "example_text = \"I am having issues with my credit card. The bank charged me an annual fee even though they said it would be waived.\"\n",
    "predicted_category = predict_complaint_category(example_text, model, tokenizer, label_mapping)\n",
    "print(f\"Predicted category: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example complaints\n",
    "test_complaints = [\n",
    "    \"I am having issues with my credit card. The bank charged me an annual fee even though they said it would be waived.\",\n",
    "    \"My credit report shows incorrect information. There are accounts listed that don't belong to me.\",\n",
    "    \"I requested a loan modification three months ago, but I haven't heard anything back from the lender.\",\n",
    "    \"A debt collector keeps calling me for a debt that isn't mine. I've told them multiple times it's not my debt.\",\n",
    "    \"I cannot access my bank account online. The website keeps showing an error message.\"\n",
    "]\n",
    "\n",
    "# Predict categories\n",
    "for i, complaint in enumerate(test_complaints):\n",
    "    category = predict_complaint_category(complaint, model, tokenizer, label_mapping)\n",
    "    print(f\"Complaint {i+1}: {complaint[:50]}...\")\n",
    "    print(f\"Predicted category: {category}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
