{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2192f595",
   "metadata": {},
   "source": [
    "# Consumer Complaint Classification â€“ Transformers \n",
    "\n",
    "## Introduction  \n",
    "\n",
    "The goal of this project is to develop a **text classification model** that categorizes **consumer complaints** into five financial categories using **transformer-based algorithms**.  \n",
    "\n",
    "The dataset, obtained from the **Consumer Financial Protection Bureau (CFPB)**, contains **over 2 million consumer complaints** from **2011 to 2024**. Each complaint is a textual **narrative** describing a financial issue, and these complaints have been labeled into **five main categories**:  \n",
    "\n",
    "- **Loans**  \n",
    "- **Credit Reporting**  \n",
    "- **Bank Accounts & Services**  \n",
    "- **Debt Collection**  \n",
    "- **Credit Card Services**  \n",
    "\n",
    "---\n",
    "\n",
    "## Data Understanding  \n",
    "\n",
    "The dataset originates from the **Consumer Complaint Database** maintained by the **Consumer Financial Protection Bureau (CFPB)**, a **U.S. federal agency** that mediates disputes between financial institutions and consumers. Consumers submit complaints through an **online form**, detailing their financial issues.  \n",
    "\n",
    "The dataset was **downloaded from the CFPB website** and underwent **preprocessing** to prepare it for NLP tasks. The key modifications include:  \n",
    "\n",
    "- Retaining only records where a **\"Consumer complaint narrative\"** is available.  \n",
    "- Reducing the dataset from **5,842,373** records to **2,023,066** entries.  \n",
    "- Renaming the **\"Consumer complaint narrative\"** column to **\"narrative\"** for ease of coding.  \n",
    "- Consolidating **18 original product categories** into **5 main categories (product_5)** to address overlaps in classification.  \n",
    "\n",
    "---\n",
    "\n",
    "## Consumer Complaint Classification Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4fbd1110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "# !pip install transformers datasets pandas numpy scikit-learn torch tqdm\n",
    "\n",
    "# --------------------\n",
    "# Standard Libraries\n",
    "# --------------------\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "# --------------------\n",
    "# Data Manipulation\n",
    "# --------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --------------------\n",
    "# Visualization\n",
    "# --------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# --------------------\n",
    "# Machine Learning\n",
    "# --------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# --------------------\n",
    "# PyTorch & Transformers\n",
    "# --------------------\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    DistilBertTokenizer,\n",
    "    DistilBertForSequenceClassification,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    RobertaTokenizer, \n",
    "    RobertaForSequenceClassification\n",
    ")\n",
    "\n",
    "# --------------------\n",
    "# Progress Bar\n",
    "# --------------------\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --------------------\n",
    "# Parameter-Efficient Fine-Tuning (LoRA)\n",
    "# --------------------\n",
    "from peft import get_peft_model, LoraModel ,LoraConfig, TaskType, PrefixEncoder, PrefixTuningConfig, IA3Config, IA3Model\n",
    "# --------------------\n",
    "# Pickle\n",
    "# --------------------\n",
    "import pickle\n",
    "# --------------------\n",
    "# Set Seed for Reproducibility\n",
    "# --------------------\n",
    "def set_seed(seed_value=42):\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# --------------------\n",
    "# Device Configuration\n",
    "# --------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a42b5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product_5",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "narrative",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Product",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date received",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sub-product",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Issue",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Sub-issue",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Company",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "State",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Timely response?",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d1f98e97-d410-45c6-8a15-37554e6143c4",
       "rows": [
        [
         "0",
         "234",
         "Credit Reporting",
         "Dear Possible Financial Inc you guyss aree reporting to the Credit bureaus that I have a charge off and Collection with you guys on XXXX and just a charge off on XXXX. None of these show on my XXXX Credit Report. I know this could be a minor mistake on you guys end I see you guys already HAVE 192 complaints about credit reporting already from XXXX. \nIm unaware of this debt I didnt have I didnt have an opportunity to dispute this information if in fact you believe you gave me proper notification then please send me the certify mail receipt with my signature on it. Also can you guys let me know your ways of verifying this my debt. \nAccount number : XXXX",
         "Credit reporting or other personal consumer reports",
         "2024-07-27",
         "Credit reporting",
         "Incorrect information on your report",
         "Account information incorrect",
         "Possible Financial Inc",
         "MI",
         "Yes"
        ],
        [
         "1",
         "240",
         "Debt Collection",
         "XXXX XXXX XXXX ( debt collector ), sent my boyfriend an email with my name, and statement of a debt owed to Spotloan. I never applied for a loan nor received a loan from this company. My boyfriend was told via phone ( contacted them after receiving this ), that I was being sued for an outstanding debt to Spotloan and that they sent the documents to my HR dept. Where I work. My boyfriend set up a payment plan and paid {$210.00}.",
         "Debt collection",
         "2024-07-27",
         "I do not know",
         "Threatened to contact someone or share information improperly",
         "Talked to a third-party about your debt",
         "BlueChip Financial",
         "TX",
         "Yes"
        ],
        [
         "2",
         "257",
         "Credit Reporting",
         "I been receiving alerts my information was found in dark web, I have inquiries on my credit that i did not authorized I have called companies they are not able to give me any information",
         "Credit reporting or other personal consumer reports",
         "2024-07-23",
         "Credit reporting",
         "Improper use of your report",
         "Credit inquiries on your report that you don't recognize",
         "FC HoldCo LLC",
         "SC",
         "Yes"
        ],
        [
         "3",
         "271",
         "Credit Reporting",
         "Subject : Dispute of Inaccurate Information on CoreLogic, XXXX, and XXXX Report and Request for Detailed Description of Verification Methods To Whom It May Concern, Details of Complaint : I am writing to formally dispute inaccurate information on my CoreLogic, XXXX, and XXXX consumer report. Upon reviewing my report, I identified several discrepancies that need correction for a fair assessment of my creditworthiness. Accurate reporting is essential, and I believe the current inaccuracies may adversely affect my financial opportunities. \nDespite previous attempts to rectify these issues through the standard dispute process, the items in question were not properly verified. Therefore, I am now requesting a Detailed Description of the Verification Methods used during the investigation of my dispute. \nSpecifically, I request the following details regarding your investigation : XXXX. Methods Used : Please describe the specific methods and procedures used to verify the disputed information. \nXXXX. Sources Consulted : Provide a list of all sources, including creditors or data furnishers, consulted during the investigation. \nXXXX. Documentation Reviewed : Detail any documentation or evidence reviewed to support the verification of the disputed information. \nXXXX. Verification Process : Explain how the accuracy of the information was verified and the criteria used for validation. \nXXXX. Timeline of Investigation : Outline the timeline of the investigation, including key dates and actions taken. \nViolations of Law : I believe the verification process by XXXX may violate my rights under the following laws : XXXX. 15 U.S.C. 1681e ( b ) : Compliance procedures to ensure maximum possible accuracy of consumer reports. \nXXXX. 15 U.S.C. 1681i : Procedure in case of disputed accuracy. \nXXXX. 15 U.S.C. 1681s-2 ( a ) ( 1 ) : Responsibility of furnishers of information to provide accurate information. \nXXXX. 12 CFR 1022.42 : General requirements for reasonable investigation of disputes. \nXXXX. 15 U.S.C. 1681c ( a ) ( 5 ) : Prohibition of adverse information older than seven years.\n\nI request the Consumer Financial Protection Bureau ( CFPB ) facilitate a thorough reinvestigation of the disputed information in my CoreLogic, XXXX, and XXXX report. Specifically, I ask that : XXXX. CoreLogic, XXXX, and XXXX provides a detailed description of their reinvestigation process and how they verified the disputed information. \nXXXX. CoreLogic, XXXX, and XXXX corrects the inaccuracies in my report as identified. \nEnclosed are copies of my CoreLogic, XXXX, and XXXX report highlighting the disputed items and any supporting documentation ( e.g., payment records, correspondence ) that proves my claim. Please review this information and correct the inaccuracies promptly. Under the FCRA, you are required to investigate my dispute within 30 days.",
         "Credit reporting or other personal consumer reports",
         "2024-07-27",
         "Credit reporting",
         "Improper use of your report",
         "Reporting company used your report improperly",
         "CORELOGIC INC",
         "GA",
         "Yes"
        ],
        [
         "4",
         "276",
         "Loans",
         "They allowed me to use the account for about a month let me get a credit builder loan and payday loan and as soon as I did that they blocked my account. They arent allowing me to access the account and havent stopped taking money.",
         "Payday loan, title loan, personal loan, or advance loan",
         "2024-07-26",
         "Payday loan",
         "Received a loan you didn't apply for",
         null,
         "MoneyLion Inc.",
         "PA",
         "Yes"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>product_5</th>\n",
       "      <th>narrative</th>\n",
       "      <th>Product</th>\n",
       "      <th>Date received</th>\n",
       "      <th>Sub-product</th>\n",
       "      <th>Issue</th>\n",
       "      <th>Sub-issue</th>\n",
       "      <th>Company</th>\n",
       "      <th>State</th>\n",
       "      <th>Timely response?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>234</td>\n",
       "      <td>Credit Reporting</td>\n",
       "      <td>Dear Possible Financial Inc you guyss aree rep...</td>\n",
       "      <td>Credit reporting or other personal consumer re...</td>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Incorrect information on your report</td>\n",
       "      <td>Account information incorrect</td>\n",
       "      <td>Possible Financial Inc</td>\n",
       "      <td>MI</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>240</td>\n",
       "      <td>Debt Collection</td>\n",
       "      <td>XXXX XXXX XXXX ( debt collector ), sent my boy...</td>\n",
       "      <td>Debt collection</td>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>I do not know</td>\n",
       "      <td>Threatened to contact someone or share informa...</td>\n",
       "      <td>Talked to a third-party about your debt</td>\n",
       "      <td>BlueChip Financial</td>\n",
       "      <td>TX</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>257</td>\n",
       "      <td>Credit Reporting</td>\n",
       "      <td>I been receiving alerts my information was fou...</td>\n",
       "      <td>Credit reporting or other personal consumer re...</td>\n",
       "      <td>2024-07-23</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>Credit inquiries on your report that you don't...</td>\n",
       "      <td>FC HoldCo LLC</td>\n",
       "      <td>SC</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>271</td>\n",
       "      <td>Credit Reporting</td>\n",
       "      <td>Subject : Dispute of Inaccurate Information on...</td>\n",
       "      <td>Credit reporting or other personal consumer re...</td>\n",
       "      <td>2024-07-27</td>\n",
       "      <td>Credit reporting</td>\n",
       "      <td>Improper use of your report</td>\n",
       "      <td>Reporting company used your report improperly</td>\n",
       "      <td>CORELOGIC INC</td>\n",
       "      <td>GA</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276</td>\n",
       "      <td>Loans</td>\n",
       "      <td>They allowed me to use the account for about a...</td>\n",
       "      <td>Payday loan, title loan, personal loan, or adv...</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>Payday loan</td>\n",
       "      <td>Received a loan you didn't apply for</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MoneyLion Inc.</td>\n",
       "      <td>PA</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         product_5  ... State Timely response?\n",
       "0         234  Credit Reporting  ...    MI              Yes\n",
       "1         240   Debt Collection  ...    TX              Yes\n",
       "2         257  Credit Reporting  ...    SC              Yes\n",
       "3         271  Credit Reporting  ...    GA              Yes\n",
       "4         276             Loans  ...    PA              Yes\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data/complaints.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "88047f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'Unnamed: 0' column\n",
    "df = df.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bd16359d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_5\n",
       "Bank Accounts and Services    10000\n",
       "Credit Card Services          10000\n",
       "Credit Reporting              10000\n",
       "Debt Collection               10000\n",
       "Loans                         10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define sample size per category\n",
    "sample_size = 10000\n",
    "\n",
    "df_resampled = df.groupby(\"product_5\").sample(n=sample_size, random_state=42)\n",
    "\n",
    "df_resampled = df_resampled.reset_index(drop=True)\n",
    "\n",
    "df_resampled[\"product_5\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "209c992d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Label mapping (int â†’ class name):\n",
      "0: Bank Accounts and Services\n",
      "1: Credit Card Services\n",
      "2: Credit Reporting\n",
      "3: Debt Collection\n",
      "4: Loans\n"
     ]
    }
   ],
   "source": [
    "# Encode the labels (LabelEncoder: str â†’ int)\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(df_resampled['product_5'])\n",
    "\n",
    "# Create label mapping (int â†’ str) for interpretation later\n",
    "label_mapping = dict(zip(range(len(label_encoder.classes_)), label_encoder.classes_))\n",
    "reverse_label_mapping = {v: k for k, v in label_mapping.items()}  # Optional reverse\n",
    "\n",
    "# Print the mapping for verification\n",
    "print(\"\\nLabel mapping (int â†’ class name):\")\n",
    "for i, label in label_mapping.items():\n",
    "    print(f\"{i}: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc1801e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set size: 35000\n",
      "Validation set size: 7500\n",
      "Test set size: 7500\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
    "    df_resampled['narrative'].values,\n",
    "    encoded_labels,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=encoded_labels\n",
    ")\n",
    "\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    temp_texts,\n",
    "    temp_labels,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {len(train_texts)}\")\n",
    "print(f\"Validation set size: {len(val_texts)}\")\n",
    "print(f\"Test set size: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82465a4b",
   "metadata": {},
   "source": [
    "Transformers settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f59909d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SELECT MODEL TYPE ===\n",
    "robertA_base = False\n",
    "distilbert = True  # Set the one you want to True\n",
    "distilbert_save= True\n",
    "robertA_base_save = False\n",
    "\n",
    "# === SELECT  Parameter-efficient Fine-tuning TYPE ===\n",
    "use_lora = True\n",
    "use_prefix = False\n",
    "use_ia3 = False\n",
    "# === AUTOMATIC CONFIG BASED ON FLAGS ===\n",
    "if distilbert:\n",
    "    model_name = 'distilbert-base-uncased'\n",
    "    model_type = 'distilbert'\n",
    "    batch_size = 16  # You can keep it higher for smaller models\n",
    "    model_save_path = 'checkpoints_distilbert' if distilbert_save else None\n",
    "    metric_save_path = 'metrics_distilbert'\n",
    "elif robertA_base:\n",
    "    model_name = 'roberta-base'\n",
    "    model_type = 'roberta'\n",
    "    batch_size = 16\n",
    "    model_save_path= 'checkpoints_roberta' if robertA_base_save else None\n",
    "    metric_save_path = 'metrics_roberta'\n",
    "\n",
    "else:\n",
    "    raise ValueError(\"Please set one of the model flags to True.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60043dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom dataset\n",
    "class ConsumerComplaintDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=512):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        text = text.strip()\n",
    "\n",
    "        # Tokenize the text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1bca8779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "if model_type == 'distilbert':\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label_mapping),\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False\n",
    "    )\n",
    "elif model_type == 'roberta':\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=len(label_mapping),\n",
    "        output_attentions=False,\n",
    "        output_hidden_states=False\n",
    "    )\n",
    "# Create datasets\n",
    "train_dataset = ConsumerComplaintDataset(train_texts, train_labels, tokenizer)\n",
    "val_dataset = ConsumerComplaintDataset(val_texts, val_labels, tokenizer)\n",
    "test_dataset = ConsumerComplaintDataset(test_texts, test_labels, tokenizer)\n",
    "\n",
    "batch_size = 16\n",
    "# Create data loaders\n",
    "if robertA_base_large:\n",
    "    batch_size = 8\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b55b3f",
   "metadata": {},
   "source": [
    "# Configure LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "61906e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'distilbert':\n",
    "    target_modules_ = [\"q_lin\", \"v_lin\"]\n",
    "if model_type == 'roberta':\n",
    "    target_modules_ = [\"q\", \"v\"]\n",
    "lora_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,     # Sequence classification\n",
    "    r=8,                             # Rank of LoRA\n",
    "    lora_alpha=16,                  # Scaling\n",
    "    target_modules=target_modules_,\n",
    "    lora_dropout=0.1,               # Dropout on LoRA layers\n",
    "    bias=\"none\"                     # Can be \"none\", \"all\", or \"lora_only\"\n",
    ")\n",
    "prefix_config = PrefixTuningConfig(\n",
    "    peft_type=\"PREFIX_TUNING\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    num_virtual_tokens=20,\n",
    "    token_dim=768,\n",
    "    num_transformer_submodules=1,\n",
    "    num_attention_heads=12,\n",
    "    num_layers=12,\n",
    "    encoder_hidden_size=768,\n",
    ")\n",
    "ia3_config = IA3Config(\n",
    "    peft_type=\"IA3\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\",\n",
    "    target_modules=[\"k\", \"v\", \"w0\"],\n",
    "    feedforward_modules=[\"w0\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6aa6e54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoraModel(\n",
       "  (model): DistilBertForSequenceClassification(\n",
       "    (distilbert): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0-5): 6 x TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): lora.Linear(\n",
       "                (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): lora.Linear(\n",
       "                (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "                (lora_magnitude_vector): ModuleDict()\n",
       "              )\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if use_lora:\n",
    "# Inject LoRA adapters\n",
    "    lora_model = LoraModel(model, lora_config, \"default\")\n",
    "    #lora_model.print_trainable_parameters()  # Optional: confirm reduced trainable params\n",
    "    model = lora_model\n",
    "if use_ia3:\n",
    "    ia3_model = IA3Model(model, ia3_config)\n",
    "    model = ia3_model\n",
    "if use_prefix and model_type == 'roberta':\n",
    "    model = get_peft_model(model, prefix_config)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ebd29ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, val_dataloader, epochs=4, learning_rate=5e-5, save_every_n_epochs=3, model_save_path=\"model\"):\n",
    "    # Prepare optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "    \n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "    \n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=0, \n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Lists to store loss and accuracy\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    val_precisions = []\n",
    "    val_recalls = []\n",
    "    val_f1s = []\n",
    "    iteration_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "        print('-' * 40)\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        progress_bar = tqdm(train_dataloader, desc=\"Training\")\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Clear previous gradients\n",
    "            model.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_train_loss += loss.item()\n",
    "            iteration_losses.append(loss.item())\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Clip the norm of the gradients to 1.0\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            \n",
    "            # Update parameters and learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(f\"Average training loss: {avg_train_loss:.4f}\")\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        predictions = []\n",
    "        true_labels = []\n",
    "        \n",
    "        for batch in tqdm(val_dataloader, desc=\"Validation\"):\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass without gradient calculation\n",
    "            with torch.no_grad():\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids,\n",
    "                    attention_mask=attention_mask,\n",
    "                    labels=labels\n",
    "                )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            total_val_loss += loss.item()\n",
    "            \n",
    "            # Get predictions\n",
    "            logits = outputs.logits\n",
    "            preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "            \n",
    "            # Store predictions and true labels\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        avg_val_loss = total_val_loss / len(val_dataloader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        val_accuracy = accuracy_score(true_labels, predictions)\n",
    "        val_precision = precision_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "        val_recall = recall_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "        val_f1 = f1_score(true_labels, predictions, average='weighted', zero_division=0)\n",
    "        val_accuracies.append(val_accuracy)\n",
    "        val_precisions.append(val_precision)\n",
    "        val_recalls.append(val_recall)\n",
    "        val_f1s.append(val_f1)\n",
    "        print(f\"Validation Loss: {avg_val_loss:.4f}\")\n",
    "        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        print(f\"Validation Precision: {val_precision:.4f}\")\n",
    "        print(f\"Validation Recall: {val_recall:.4f}\")\n",
    "        print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(true_labels, predictions))\n",
    "\n",
    "        # === Save checkpoint every N epochs ===\n",
    "        if (epoch + 1) % save_every_n_epochs == 0:\n",
    "            checkpoint_dir = os.path.join(model_save_path, f\"epoch_{epoch + 1}\")\n",
    "            os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "            model.save_pretrained(checkpoint_dir)\n",
    "            try:\n",
    "                model.config.tokenizer.save_pretrained(checkpoint_dir)  # If tokenizer is attached\n",
    "            except:\n",
    "                pass  # Or pass tokenizer separately outside\n",
    "            print(f\"Checkpoint saved to {checkpoint_dir}\")\n",
    "            '''\n",
    "            metrics = {\n",
    "        'epoch': epoch + 1,\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'iteration_losses': iteration_losses,\n",
    "        'val_precisions': val_precisions,\n",
    "        'val_recalls': val_recalls,\n",
    "        'val_f1s': val_f1s,\n",
    "        }\n",
    "    with open(os.path.join(metric_save_path, f\"metric_epoch_{epoch + 1}\"), 'wb') as f:\n",
    "        pickle.dump(metrics, f)\n",
    "        '''\n",
    "    return model, train_losses, val_losses, val_accuracies,  iteration_losses, val_precisions, val_recalls, val_f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa9c846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iteration_loss(iteration_losses):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(iteration_losses, label='Training Loss (per iteration)', linewidth=0.7)\n",
    "    plt.title('Training Loss per Iteration')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fccd268",
   "metadata": {},
   "source": [
    "## Plotting Validation Loss, Accuracy, Precision, Recall ,and F1 Score for each Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bd9ad883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_metrics(val_accuracies, val_precisions, val_recalls, val_f1s):\n",
    "    epochs = list(range(1, len(val_accuracies) + 1))\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(epochs, val_accuracies, label='Accuracy')\n",
    "    plt.plot(epochs, val_precisions, label='Precision')\n",
    "    plt.plot(epochs, val_recalls, label='Recall')\n",
    "    plt.plot(epochs, val_f1s, label='F1 Score')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.title('Validation Metrics per Epoch')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819d5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epoch_metrics(val_accuracies, val_precisions, val_recalls, val_f1s, val_losses, train_losses):\n",
    "    epochs = list(range(1, len(val_accuracies) + 1))\n",
    "\n",
    "    # Accuracy\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs, val_accuracies, label='Accuracy', color='blue', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Validation Accuracy per Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Precision\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs, val_precisions, label='Precision', color='green', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('Validation Precision per Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Recall\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs, val_recalls, label='Recall', color='orange', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.title('Validation Recall per Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # F1 Score\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs, val_f1s, label='F1 Score', color='red', marker='o')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.title('Validation F1 Score per Epoch')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Validation Loss\n",
    "    \n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs, train_losses, label='Training Loss', marker='o', color='blue')\n",
    "    plt.plot(epochs, val_losses, label='Validation Loss', marker='o', color='orange')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train vs Validation Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b970602e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf038dbfde444f892db582db13e052d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/2188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Training parameters ===\n",
    "epochs = 3\n",
    "learning_rate = 5e-5\n",
    "\n",
    "# === Train the model ===\n",
    "model, train_losses, val_losses, val_accuracies, iteration_losses, val_precisions, val_recalls, val_f1s = train_model(\n",
    "    model,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    epochs=epochs,\n",
    "    learning_rate=learning_rate,\n",
    "    save_every_n_epochs=3,\n",
    "    model_save_path=model_save_path\n",
    ")\n",
    "'''\n",
    "# === Save the model ===\n",
    "# Convert model name (e.g., \"distilbert-base-uncased\") into a clean folder name\n",
    "model_save_path = f\"{model_name.replace('/', '_')}_consumer_complaints_model\"\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b894e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iteration_loss(iteration_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60667f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epoch_metrics(val_accuracies, val_precisions, val_recalls, val_f1s, val_losses,train_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4b1186",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    all_probs = []\n",
    "    confidences = []\n",
    "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "        # Move batch to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass without gradient calculation\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "        \n",
    "        # Get predictions\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        all_probs.extend(probs)\n",
    "        preds = np.argmax(probs, axis=1)\n",
    "        confidences_batch = np.max(probs, axis=1) \n",
    "        confidences.extend(confidences_batch)\n",
    "        # Store predictions and true labels\n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "    all_probs = np.array(all_probs)\n",
    "    true_labels = np.array(true_labels)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    true_labels_binarized = label_binarize(true_labels, classes=list(range(all_probs.shape[1])))\n",
    "    n_classes = true_labels_binarized.shape[1]\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(true_labels_binarized[:, i], all_probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    precision = precision_score(true_labels, predictions, average='weighted')\n",
    "    recall = recall_score(true_labels, predictions, average='weighted')\n",
    "    f1 = f1_score(true_labels, predictions, average='weighted')\n",
    "    \n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Test Precision: {precision:.4f}\")\n",
    "    print(f\"Test Recall: {recall:.4f}\")\n",
    "    print(f\"Test F1 Score: {f1:.4f}\")\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, predictions))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(true_labels, predictions)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=label_encoder.classes_, \n",
    "                yticklabels=label_encoder.classes_)\n",
    "    plt.title('Confusion Matrix', fontsize=16)\n",
    "    plt.xlabel('Predicted Label', fontsize=14)\n",
    "    plt.ylabel('True Label', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'true_labels': true_labels,\n",
    "        'all_probs': all_probs,\n",
    "        'predictions': predictions,\n",
    "        'confidences': confidences\n",
    "    }\n",
    "\n",
    "# Add missing import for confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_results = evaluate_model(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12247fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_auc_curve(true_labels, all_probs, label_encoder):\n",
    "    true_labels_binarized = label_binarize(true_labels, classes=list(range(all_probs.shape[1])))\n",
    "    n_classes = true_labels_binarized.shape[1]\n",
    "\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(true_labels_binarized[:, i], all_probs[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    for i in range(n_classes):\n",
    "        plt.plot(fpr[i], tpr[i], lw=1.5, label=f\"{label_encoder.classes_[i]} (AUC = {roc_auc[i]:.2f})\")\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=1, label='Chance')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Multi-Class ROC-AUC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2bd55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_auc_curve(test_results[\"true_labels\"], test_results[\"all_probs\"], label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5642acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curve(true_labels, predicted_labels, confidences):\n",
    "    # Convert to binary: 1 if prediction is correct\n",
    "    correct = (np.array(true_labels) == np.array(predicted_labels)).astype(int)\n",
    "\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "        correct,\n",
    "        confidences,\n",
    "        n_bins=10\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.plot(mean_predicted_value, fraction_of_positives, marker='o', label='Model Calibration')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfect Calibration')\n",
    "    plt.xlabel('Mean Predicted Confidence')\n",
    "    plt.ylabel('Fraction of Correct Predictions')\n",
    "    plt.title('Confidence Calibration Curve')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f12074",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_calibration_curve(test_results[\"true_labels\"], test_results[\"predictions\"], test_results[\"confidences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63029298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_complaint_category(text, model, tokenizer, label_mapping):\n",
    "    # Tokenize the text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    # Move inputs to the device\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Forward pass without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Get the predictions\n",
    "    logits = outputs.logits\n",
    "    prediction_id = torch.argmax(logits, dim=1).item()\n",
    "    \n",
    "    # Get the predicted category\n",
    "    predicted_category = label_mapping[prediction_id]\n",
    "    \n",
    "    return predicted_category\n",
    "\n",
    "# Example usage\n",
    "example_text = \"I am having issues with my credit card. The bank charged me an annual fee even though they said it would be waived.\"\n",
    "predicted_category = predict_complaint_category(example_text, model, tokenizer, label_mapping)\n",
    "print(f\"Predicted category: {predicted_category}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de1b49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example complaints\n",
    "test_complaints = [\n",
    "    \"I am having issues with my credit card. The bank charged me an annual fee even though they said it would be waived.\",\n",
    "    \"My credit report shows incorrect information. There are accounts listed that don't belong to me.\",\n",
    "    \"I requested a loan modification three months ago, but I haven't heard anything back from the lender.\",\n",
    "    \"A debt collector keeps calling me for a debt that isn't mine. I've told them multiple times it's not my debt.\",\n",
    "    \"I cannot access my bank account online. The website keeps showing an error message.\"\n",
    "]\n",
    "\n",
    "# Predict categories\n",
    "for i, complaint in enumerate(test_complaints):\n",
    "    category = predict_complaint_category(complaint, model, tokenizer, label_mapping)\n",
    "    print(f\"Complaint {i+1}: {complaint[:50]}...\")\n",
    "    print(f\"Predicted category: {category}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
